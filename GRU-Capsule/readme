1.词向量模型使用大致有两种，一种是对三种词向量模型取平均值，另一种则是将三种词向量模型拼接起来一起输入。前者仍然维持了词向量300维的维度，但是后者则会使得词向量的维度翻倍增大，embedding层的输入变得很大，这样使得运行变慢，这个比赛要求代码能在7200秒内运行出来，否则不计成绩。因此取拼接的方法虽然能够取得更多的信息，但是时间上很紧张，但是确实前几名的人是用拼接的方法做的；
2.K折。这个可以在下面的代码中看到，使用K折的方法可以不断改进模型，使得模型更好。实际效果确实也是很好的，但是K折同样使得时间成倍增加，一般4~5折是比较经济的做法；
3.以f1-score作为评价标准时需要调整感知机的threshold，在这个比赛中threshold一般取在0.2~0.3的效果是比较好的；
4.评论语句的预处理。这里其实还是想了很多的，比如很多单词可能根本就是不存在于词袋中的，还有很多特殊字符等。代码中只是单纯将特殊字符两侧添加空格。其实还有很多其他可以处理的方法：大写转小写，连续数字使用"n"或者"1"替代，再比如一些连字符可以直接用空格替代掉，将连字符两端的单词分别单独处理。
